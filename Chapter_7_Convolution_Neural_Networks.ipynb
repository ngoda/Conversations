{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngoda/Conversations/blob/master/Chapter_7_Convolution_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qoSqsBhNWKlk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copying Files from Google Drive to Colab Parent Directory"
      ],
      "metadata": {
        "id": "pdi7c3V2irVZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VMYmJ2JhiUL",
        "outputId": "6fa0825d-b849-4339-f922-dc8788bbd13f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder copied successfully from child folder to parent path.\n"
          ]
        }
      ],
      "source": [
        "#Copy Files & Directories from one source to destinition\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Define the source directory (child folder) and the destination directory (parent path)\n",
        "source_dir = '/content/drive/MyDrive/Colab Notebooks/data2'\n",
        "destination_dir = '/content'\n",
        "\n",
        "# List the contents of the source directory\n",
        "source_contents = os.listdir(source_dir)\n",
        "\n",
        "# Copy each file/folder from the source directory to the destination directory\n",
        "for item in source_contents:\n",
        "    # Form the source and destination paths\n",
        "    source_path = os.path.join(source_dir, item)\n",
        "    destination_path = os.path.join(destination_dir, item)\n",
        "\n",
        "    # Check if the item is a file or a directory\n",
        "    if os.path.isfile(source_path):\n",
        "        # Use shutil.copy() to copy files\n",
        "        shutil.copy(source_path, destination_path)\n",
        "    elif os.path.isdir(source_path):\n",
        "        # Use shutil.copytree() to copy directories recursively\n",
        "        shutil.copytree(source_path, destination_path)\n",
        "\n",
        "print(\"Folder copied successfully from child folder to parent path.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convolution Neural Networks**\n",
        "\n",
        " **Implementing a convolution Layer**\n",
        "\n",
        " The code generates random image tensors, converts them to column representations with the im2col function, then outputs the resulting shapes."
      ],
      "metadata": {
        "id": "i8NdEc14iqbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries and modules\n",
        "import numpy as np  # Importing numpy and abbreviating it as np\n",
        "import sys, os  # Importing sys and os modules\n",
        "\n",
        "# Appending the parent directory to the system path\n",
        "sys.path.append(os.pardir)\n",
        "\n",
        "# Importing the im2col function from the common.util module\n",
        "from common.util import im2col\n",
        "\n",
        "# Generating a random input image tensor x1 with shape (1, 3, 7, 7)\n",
        "x1 = np.random.rand(1, 3, 7, 7)\n",
        "\n",
        "# Converting the input image tensor x1 into a column representation using im2col\n",
        "col1 = im2col(x1, 5, 5, stride=1, pad=0)\n",
        "\n",
        "# Printing the shape of the column representation col1\n",
        "print(col1.shape)  # Expected output: (9,75)\n",
        "\n",
        "# Generating a random input image tensor x2 with shape (10, 3, 7, 7)\n",
        "x2 = np.random.rand(10, 3, 7, 7)\n",
        "\n",
        "# Converting the input image tensor x2 into a column representation using im2col\n",
        "col2 = im2col(x2, 5, 5, stride=1, pad=0)\n",
        "\n",
        "# Printing the shape of the column representation col2\n",
        "print(col2.shape)  # Expected output: (90,75)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2g4yyA2JkC04",
        "outputId": "a0bf9b6f-97e8-4356-b2d4-74cad845eb2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9, 75)\n",
            "(90, 75)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementing a convolution Layer**\n",
        "\n",
        "Code2 - 9 collectively represent the construction and functionality of a simple convolutional neural network for image classification."
      ],
      "metadata": {
        "id": "gbHV1NaDrfyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Code #2\n",
        "#Defines the Convolution class responsible for performing convolution operations.\n",
        "#It includes methods for initialization (__init__) and forward pass computation (forward).\n",
        "class Convolution:\n",
        "    def __init__(self, W, b, stride=1, pad=0):\n",
        "        # Initialize the Convolutional layer with weights, biases, stride, and padding\n",
        "        self.W = W  # Weights\n",
        "        self.b = b  # Biases\n",
        "        self.stride = stride  # Stride\n",
        "        self.pad = pad  # Padding\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Perform forward pass computation of the Convolutional layer\n",
        "        FN, C, FH, FW = self.W.shape  # Number of filters, Number of channels, Filter height, Filter width\n",
        "        N, C, H, W = x.shape  # Batch size, Number of channels, Input height, Input width\n",
        "        out_h = int(1 + (H + 2*self.pad - FH) / self.stride)  # Compute output height\n",
        "        out_w = int(1 + (W + 2*self.pad - FW) / self.stride)  # Compute output width\n",
        "        col = im2col(x, FH, FW, self.stride, self.pad)  # Convert input to column matrix\n",
        "        col_W = self.W.reshape(FN, -1).T  # Reshape filters to columns\n",
        "        out = np.dot(col, col_W) + self.b  # Perform convolution operation\n",
        "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)  # Reshape output and transpose dimensions\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Code #3\n",
        "#Defines the col2im function, which performs the reverse operation of im2col,\n",
        "#converting column representations back to the original input shape.\n",
        "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
        "    # Unpack input_shape into variables\n",
        "    N, C, H, W = input_shape\n",
        "    # Compute output height and width\n",
        "    out_h = (H + 2*pad - filter_h) // stride + 1\n",
        "    out_w = (W + 2*pad - filter_w) // stride + 1\n",
        "    # Reshape col into appropriate shape and transpose dimensions\n",
        "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
        "\n",
        "    # Initialize output image array with zeros\n",
        "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
        "    # Iterate over filter height\n",
        "    for y in range(filter_h):\n",
        "        # Calculate the maximum y position for the current stride\n",
        "        y_max = y + stride*out_h\n",
        "        # Iterate over filter width\n",
        "        for x in range(filter_w):\n",
        "            # Calculate the maximum x position for the current stride\n",
        "            x_max = x + stride*out_w\n",
        "            # Accumulate values from col into img using slicing\n",
        "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
        "    # Return the cropped image without padding\n",
        "    return img[:, :, pad:H+pad, pad:W+pad]\n",
        "\n",
        "\n",
        "\n",
        "# Code #4\n",
        "#Defines the Pooling class for implementing pooling operations (specifically max pooling).\n",
        "#It includes methods for forward pass computation (forward) and backward pass computation (backward).\n",
        "class Pooling:\n",
        "    def __init__(self, pool_h, pool_w, stride=2, pad=0):\n",
        "        # Initialize the Pooling layer with pool height, pool width, stride, and padding\n",
        "        self.pool_h = pool_h  # Pool height\n",
        "        self.pool_w = pool_w  # Pool width\n",
        "        self.stride = stride  # Stride\n",
        "        self.pad = pad  # Padding\n",
        "        self.x = None  # Initialize input variable\n",
        "        self.arg_max = None  # Initialize variable to store indices of max values\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Perform forward pass computation of the Pooling layer\n",
        "        N, C, H, W = x.shape  # Batch size, Number of channels, Input height, Input width\n",
        "        out_h = int(1 + (H - self.pool_h) / self.stride)  # Compute output height\n",
        "        out_w = int(1 + (W - self.pool_w) / self.stride)  # Compute output width\n",
        "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)  # Convert input to column matrix\n",
        "        col = col.reshape(-1, self.pool_h*self.pool_w)  # Reshape columns\n",
        "        arg_max = np.argmax(col, axis=1)  # Find indices of max values\n",
        "        out = np.max(col, axis=1)  # Perform max pooling operation\n",
        "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)  # Reshape output and transpose dimensions\n",
        "        self.x = x  # Save input for backward pass\n",
        "        self.arg_max = arg_max  # Save indices of max values for backward pass\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        # Perform backward pass computation of the Pooling layer\n",
        "        dout = dout.transpose(3, 2, 1, 0)  # Transpose input gradient\n",
        "        pool_size = self.pool_h * self.pool_w  # Compute pool size\n",
        "        dmax = np.zeros((dout.size, pool_size))  # Initialize array for gradients\n",
        "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()  # Set gradients at max indices\n",
        "        dmax = dmax.reshape(dout.shape + (pool_size,))  # Reshape gradients\n",
        "        dx = col2im(dmax, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)  # Convert to image shape\n",
        "        return dx  # Return gradient of the input\n",
        "\n",
        "\n",
        "\n",
        "# Code #5\n",
        "#Defines the SimpleConvNet class, which represents a simple convolutional neural network.\n",
        "#It includes initialization and methods for prediction (predict), loss computation (loss), and gradient computation (gradient).\n",
        "class SimpleConvNet:\n",
        "    def __init__(self, input_dim=(1, 28, 28), conv_param={'filter_num':30, 'filter_size':5, 'pad':8, 'stride':1}, hidden_size=100, output_size=10, weight_init_std=0.01):\n",
        "        # Initialize SimpleConvNet with input dimensions, convolutional parameters, hidden size, output size, and weight initialization standard deviation\n",
        "        filter_num = conv_param['filter_num']  # Number of filters\n",
        "        filter_size = conv_param['filter_size']  # Size of filters\n",
        "        filter_pad = conv_param['pad']  # Padding size\n",
        "        filter_stride = conv_param['stride']  # Stride size\n",
        "        input_size = input_dim[1]  # Input size\n",
        "        conv_output_size = (input_size + 2*filter_pad - filter_size) / filter_stride + 1  # Compute convolution output size\n",
        "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))  # Compute pooling output size\n",
        "\n",
        "\n",
        "\n",
        "# Code #6\n",
        "# Initializes the parameters of the convolutional neural network (CNN) including weights and biases.\n",
        "        self.params = {}  # Initialize dictionary to store parameters\n",
        "\n",
        "        # Initialize and randomly initialize the weights and biases for the first convolutional layer\n",
        "        self.params['W1'] = weight_init_std * np.random.randn(filter_num, input_dim[0], filter_size, filter_size)  # Filter weights\n",
        "        self.params['b1'] = np.zeros(filter_num)  # Filter biases\n",
        "\n",
        "        # Initialize and randomly initialize the weights and biases for the second fully connected layer\n",
        "        self.params['W2'] = weight_init_std * np.random.randn(pool_output_size, hidden_size)  # Fully connected layer weights\n",
        "        self.params['b2'] = np.zeros(hidden_size)  # Fully connected layer biases\n",
        "\n",
        "        # Initialize and randomly initialize the weights and biases for the third fully connected layer\n",
        "        self.params['W3'] = weight_init_std * np.random.randn(hidden_size, output_size)  # Fully connected layer weights\n",
        "        self.params['b3'] = np.zeros(output_size)  # Fully connected layer biases\n",
        "\n",
        "\n",
        "\n",
        "# Code #7\n",
        "#Constructs the layers of the CNN using the defined classes (Convolution, Relu, Pooling, Affine, SoftmaxWithLoss).\n",
        "#It sets up the layers in order and initializes the last layer as the softmax with loss layer.\n",
        "        self.layers = OrderedDict()  # Initialize OrderedDict to store layers\n",
        "\n",
        "        # Add layers to the network architecture\n",
        "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'], conv_param['stride'], conv_param['pad'])  # First Convolutional layer\n",
        "        self.layers['Relu1'] = Relu()  # First ReLU activation layer\n",
        "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)  # First Pooling layer\n",
        "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])  # First Fully Connected (Affine) layer\n",
        "        self.layers['Relu2'] = Relu()  # Second ReLU activation layer\n",
        "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])  # Second Fully Connected (Affine) layer\n",
        "        self.last_layer = SoftmaxWithLoss()  # Softmax with Loss layer\n",
        "\n",
        "\n",
        "# Code #8\n",
        "#Defines the predict and loss methods for the CNN, which compute predictions and loss values respectively.\n",
        "    def predict(self, x):\n",
        "        # Perform forward pass prediction through all layers in the network\n",
        "        for layer in self.layers.values():\n",
        "            x = layer.forward(x)  # Forward pass through each layer\n",
        "        return x  # Return the predicted output\n",
        "\n",
        "    def loss(self, x, t):\n",
        "        # Compute the loss using forward pass prediction\n",
        "        y = self.predict(x)  # Predict output using the input data\n",
        "        return self.last_layer.forward(y, t)  # Compute the loss using the predicted output and target\n",
        "\n",
        "\n",
        "\n",
        "# Code #9\n",
        "#Defines the gradient method, which computes gradients during backpropagation.\n",
        "#It computes the loss, performs backward propagation, saves gradients, and returns them.\n",
        "    def gradient(self, x, t):\n",
        "        # Compute gradients for network parameters\n",
        "\n",
        "        # Forward pass to compute loss\n",
        "        self.loss(x, t)\n",
        "\n",
        "        # Backward pass to compute gradients\n",
        "        dout = 1  # Initialize gradient of loss with respect to output\n",
        "        dout = self.last_layer.backward(dout)  # Backward pass through the last layer\n",
        "\n",
        "        layers = list(self.layers.values())  # Get all layers in the network\n",
        "        layers.reverse()  # Reverse the order of layers for backward pass\n",
        "        for layer in layers:\n",
        "            dout = layer.backward(dout)  # Backward pass through each layer\n",
        "\n",
        "        # Save computed gradients\n",
        "        grads = {}\n",
        "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db  # Gradients for Convolutional layer\n",
        "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db  # Gradients for first Fully Connected layer\n",
        "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db  # Gradients for second Fully Connected layer\n",
        "\n",
        "        return grads  # Return the computed gradients\n",
        "\n"
      ],
      "metadata": {
        "id": "U-OMRha7FbwQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}